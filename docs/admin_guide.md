# Административная документация: Развертывание и поддержка системы Q&A

## 1. Развертывание

### 1.1 Системные требования
- OS: Windows 10+, Linux Ubuntu 18+, macOS 10.14+
- Python: 3.8-3.11
- RAM: минимум 8GB
- Диск: 10GB свободного места
- Браузер: Chrome 90+, Firefox 85+, Safari 14+

### 1.2 Установка зависимостей
1. Создайте виртуальное окружение: `python -m venv venv`
2. Активируйте: `venv\Scripts\activate` (Windows) или `source venv/bin/activate` (Linux/Mac)
3. Установите пакеты: `pip install -r requirements.txt`

#### Основные зависимости:
- sentence-transformers, chromadb, openai, gradio, python-dotenv
- ollama для локального LLM
- opcprocessing для работы с документами (если требуется)

### 1.3 Конфигурация
1. Создайте файл `.env` в корневой папке:
   ```
   DEEPSEEK_API_KEY=ваш_ключ_deepseek
   OLLAMA_BASE_URL=http://localhost:11434
   ```
2. Установите модель Ollama: `ollama pull qwen2.5:3b`

### 1.4 Подготовка данных
1. Поместите документы в `documents/docs/` (DOCX), `documents/pdfs/` (PDF), `documents/txts/` (TXT)
2. Запустите обработку документов:
   - `python src/chunking.py` - чанкирование
   - `python src/add_metadata.py` - добавление метаданных
   - `python src/embed_store.py` - эмбеддинги и сохранение в ChromaDB

### 1.5 Локальное развертывание
- Запуск: `python rag_app.py`
- Доступ: http://localhost:7860
- Для сервера: `python -m uvicorn rag_app:app --host 0.0.0.0 --port 7860` (если используется FastAPI)

### 1.6 Серверное развертывание
- **Hugging Face Spaces:** Создайте Space, загрузите код, настройте секреты, разверните через Gradio SDK
- **Docker:** Создайте Dockerfile, соберите образ, запустите контейнер
- Монитринг: Интегрируйте Prometheus/Grafana для метрик производительности

## 2. Поддержка системы

### 2.1 Мониторинг
- **Метрики поиска:** Количество запросов, популярные темы
- **Производительность:** Время отклика (<30сек на ответ), нагрузка на систему
- **Ошбики:** Логи неудачных поисков и генераций в файлах логов

### 2.2 Резервное копирование
- Ежедневное копирование `data/chroma_db/` и метаданных
- Экспорт через интерфейс администрирования
- Восстановление: копирование файлов обратно в `data/`

### 2.3 Обновление документов
1. Добавьте новые файлы в `documents/`
2. Запустите переиндексацию через админ-интерфейс
3. Процесс: очистка старых чанков, повторное чанкирование и эмбеддинг

### 2.4 Поддержка пользователей
- Модуль истории запросов для анализа трендов
- Редактирование метаданых для улучшения поиска
- Добавление новых типов документов по необходимости

### 2.5 Безопасность
- Регулярно обновляйте API ключи
- Мониторьте логи на подозрительную активность
- Валидируйте ввод для предотвращения вредоносных запросов

## 3. Решение проблем

### 3.1 Общие проблемы
- **Зависимости:** Переустановите с `pip install --upgrade -r requirements.txt`
- **API ошибки:** Проверьте ключи в `.env` и лимиты DeepSeek
- **Ollama:** Перезапустите сервис, проверьте модель `ollama list`

### 3.2 Производительность
- Оптимизация: Батчи эмбеддингов, индексация с фильтрами
- Масштабирование: Увеличьте RAM/CPU, используйте GPU для эмбеддингов

### 3.3 Восстановление из бэкапа
1. Остановите приложение
2. Восстановите файлы из бэкапа в `data/`
3. Перезапустите `rag_app.py`

## 4. Мониторинг и логи

- Логи в консоли и файлах (если настроено)
- Метрики через Gradio интерфейс администрирования
- Регулярные проверки целостности с `check_integrity.py`

## 5. Контакты

Для вопросов по развертыванию связывайтесь с командой разработчиков.
